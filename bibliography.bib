@article{Arnab_2019,
   title={Exploiting Temporal Context for 3D Human Pose Estimation in the Wild},
   ISBN={9781728132938},
   url={http://dx.doi.org/10.1109/CVPR.2019.00351},
   DOI={10.1109/cvpr.2019.00351},
   journal={2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
   publisher={IEEE},
   author={Arnab, Anurag and Doersch, Carl and Zisserman, Andrew},
   year={2019},
   month={Jun}
}


@misc{osha2019msd, 
  title="Work-related MSDs: prevalence, costs and demographics in the EU", author="de Kok,Jan
  and Vroonhof, Paul and Snijders, Jacqueline and Roullis, Georgios and Clarke, Martin and Peereboom, Kees and van Dorst, Pim and Isusi, I{\~{n}}igo", 
  year="2019", 
  publisher="European Agency for Safety and Health at Work", 
  url={https://osha.europa.eu/en/publications/summary-msds-facts-and-figures-overview-prevalence-costs-and-demographics-msds-europe/view},
  lastaccessed="February 8, 2020"
 }
  
@misc{osha2000facts,
    author= {{European Agency for Safety and Health at Work}},
    year  = {2000},
    title = {Work-related Low Back Disorders, {Fact Sheet N\textsuperscript{o}10}},
    url = {https://osha.europa.eu/en/publications/factsheet-10-work-related-low-back-disorders/view},
    lastaccessed="January 12, 2018"
}

@misc{eurostat_comp_use,
    author= {{Eurostat}},
    title = {Use of computers and the internet by employees},
    url  = {https://appsso.eurostat.ec.europa.eu/nui/show.do?query=BOOKMARK_DS-057202_QID_34F130EE_UID_-3F171EB0&layout=TIME,C,X,0;GEO,L,Y,0;INDIC_IS,L,Z,0;UNIT,L,Z,1;SIZEN_R2,L,Z,2;INDICATORS,C,Z,3;&zSelection=DS-057202INDICATORS,OBS_FLAG;DS-057202INDIC_IS,P_CUSE;DS-057202SIZEN_R2,10_C10_S951_XK;DS-057202UNIT,PC_EMP;&rankName1=UNIT_1_2_-1_2&rankName2=INDICATORS_1_2_-1_2&rankName3=INDIC-IS_1_2_-1_2&rankName4=SIZEN-R2_1_2_-1_2&rankName5=TIME_1_0_0_0&rankName6=GEO_1_2_0_1&sortC=ASC_-1_FIRST&rStp=&cStp=&rDCh=&cDCh=&rDM=true&cDM=true&footnes=false&empty=false&wai=false&time_mode=NONE&time_most_recent=false&lang=EN&cfo=\%23\%23\%23\%2C\%23\%23\%23.\%23\%23\%23}, 
    lastaccessed="February 8, 2020"
}

@inproceedings{demmans2007posture,
  title={Posture monitoring and improvement for laptop use},
  author={Demmans, Carrie and Subramanian, Sriram and Titus, Jon},
  booktitle={CHI'07 Extended Abstracts on Human Factors in Computing Systems},
  pages={2357--2362},
  year={2007}
}

@inproceedings{jaimes2005sit,
  title={Sit straight (and tell me what I did today) a human posture alarm and activity summarization system},
  author={Jaimes, Alejandro},
  booktitle={Proceedings of the 2nd ACM workshop on Continuous archival and retrieval of personal experiences},
  pages={23--34},
  year={2005}
}

@article{kaber1997out,
  title={Out-of-the-loop performance problems and the use of intermediate levels of automation for improved control system functioning and safety},
  author={Kaber, David B and Endsley, Mica R},
  journal={Process Safety Progress},
  volume={16},
  number={3},
  pages={126--131},
  year={1997},
  publisher={Wiley Online Library},
  doi={10.1002/prs.680160304}
}

@InProceedings{hoesl2017trackline,
author="Hoesl, Axel
and Aragon Bartsch, Sarah
and Butz, Andreas",
editor="Bernhaupt, Regina
and Dalvi, Girish
and Joshi, Anirudha
and K. Balkrishan, Devanuj
and O'Neill, Jacki
and Winckler, Marco",
title="TrackLine: Refining touch-to-track Interaction for Camera Motion Control on Mobile Devices",
booktitle="Human-Computer Interaction - INTERACT 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="283--292",
abstract="Controlling a film camera to follow an actor or object in an aesthetically pleasing way is a highly complex task, which takes professionals years to master. It entails several sub-tasks, namely (1) selecting or identifying and (2) tracking the object of interest, (3) specifying the intended location in the frame (e.g., at 1/3 or 2/3 horizontally) and (4) timing all necessary camera motions such that they appear smooth in the resulting footage. Traditionally, camera operators just controlled the camera directly or remotely and practiced their motions in several repeated takes until the result met their own quality criteria. Automated motion control systems today assist with the timing and tracking sub-tasks, but leave the other two to the camera operator using input methods such as touch-to-track, which still present challenges in timing and coordination. We designed a refined input method called TrackLine which decouples target and location selection and adds further automation with even improved control. In a first user study controlling a virtual camera, we compared TrackLine to touch-to-track and traditional joystick control and found that the results were objectively both more accurate and more easily achieved, which was also confirmed by the subjective ratings of our participants.",
isbn="978-3-319-67684-5",
doi={10.1007/978-3-319-67684-5_17}
}

@InProceedings{hoesl2017effects,
author="Hoesl, Axel
and Alic, Mujo
and Butz, Andreas",
editor="Bernhaupt, Regina
and Dalvi, Girish
and Joshi, Anirudha
and K. Balkrishan, Devanuj
and O'Neill, Jacki
and Winckler, Marco",
title="On the Effects of Progressive Reduction as Adaptation Strategy for a Camera-Based Cinematographic User Interface",
booktitle="Human-Computer Interaction - INTERACT 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="513--522",
abstract="Camera-based user interfaces (UI) became increasingly relevant, especially on mobile devices, with location independent media production tools such as drones. The devices traditionally render the necessary user interface elements for remote control on top of the content they display. This often leads to occlusion and visual clutter. Progressive Reduction is a recently proposed UI adaption strategy that can help to minimize these issues while maintaining usability. It exploits learning and spatial memory effects in order to gradually reduce the visual footprint of UI elements. We conducted two user studies to investigate the effects of this approach. In the first study, we compared three design alternatives to obviate interference due to design (N = 10). Based on the most promising design, we conducted a second user study (N = 18) investigating the effects of two different reduction strategies (icons-first and background-first). We collected data on perceived control, workload and creativity support in addition to semi-structured interviews. Our results indicate that there was only a minor decrease in perceived control up to a certain amount of reduction. Beyond that, however, the negative effects on perceived control become unacceptable to users. This was observed for all applied reduction strategies.",
isbn="978-3-319-67744-6",
doi={10.1007/978-3-319-67744-6_32}
}

@inproceedings{,
  title={The design and evaluation of multitouch marking menus},
  author={Lepinski, G Julian and Grossman, Tovi and Fitzmaurice, George},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2233--2242},
  year={2010},
  organization={ACM},
  doi={10.1145/1753326.1753663}
}

@phdthesis{nielsen2007camera,
title = "Camera Movement in Narrative Cinema: Towards a Taxonomy of Functions",
abstract = "Just like art historians have focused on e.g. composition or lighting, this dissertation takes a single stylistic parameter as its object of study: camera movement. Within film studies this localized avenue of middle-level research has become increasingly viable under the aegis of a perspective known as ‘the poetics of cinema.’ The dissertation embraces two branches of research within this perspective: stylistics and historical poetics (stylistic history). The dissertation takes on three questions in relation to camera movement and is accordingly divided into three major sections. The first section unearths what characterizes the literature on camera movement. The second section of the dissertation delineates the history of camera movement itself within narrative cinema. Several organizational principles subtending the on-screen effect of camera movement are revealed in section two but they are not organized into a coherent framework. This is the task that section three meets in proposing a functional taxonomy for camera movement in narrative cinema. Two presumptions subtend the taxonomy: That camera movement actively contributes to the way in which we understand the sound and images on the screen, and that a given camera movement may activate one or more of the proposed functions at any given moment. Six main functions are proposed and defined: 1) Orientation: orienting the viewer spatially.2) Pacing: contributing to the cinematic rhythm of the film.3) Inflection: inflecting shots in a suggestive, commentative or valuative manner.4) Focalization: associating the movement of the camera with the viewpoints of characters or entities in the story world.5) Reflexive: inviting spectators to engage with the artifice of camera movement. 6) Abstract: visualizing abstract ideas and concepts.In order to illustrate how the functions may mesh in individual camera movements six concrete examples are analyzed.The analyses illustrate how the taxonomy presented can substantiate analysis and interpretation of film style. More generally, the dissertation - and particularly these in-depth analyses - illustrates how cinematic poetics and interpretive criticism sensitive to style may gain from each other. There is no reason why stylistically informed interpretive criticism cannot be considered within a functional framework and there is no reason why one should not use a functional taxonomy as a basis on which to launch interpretations of film style. There is a limit to how much one can say about camera movement without a full understanding of the range of functions that they operate within but there is also a limit to how far functional analysis can take us towards establishing the contribution of a particular camera movement.",
keywords = "kamerabev\{ae}gelse, stil, \{ae}stetik, filmteori, film, camera movement, style, aesthetics, cinematography, film theory, film history",
author = "Nielsen, {Jakob Isak}",
year = "2007",
language = "English",
isbn = "87-92052-25-8",
volume = "1",
edition = "1",
}

@inproceedings{chen2014autonomous,
  title={Autonomous camera systems: A survey},
  author={Chen, Jianhui and Carr, Peter},
  booktitle={Workshops at the Twenty-Eighth AAAI Conference on Artificial Intelligence},
  volume={2},
  year={2014}
}

@article{eng2005visual,
  title={Visual working memory for simple and complex visual stimuli},
  author={Eng, Hing Yee and Chen, Diyu and Jiang, Yuhong},
  journal={Psychonomic bulletin \& review},
  volume={12},
  number={6},
  pages={1127--1133},
  year={2005},
  publisher={Springer},
  doi={10.3758/BF03206454}
}

@inproceedings{christianson1996declarative,
 author = {Christianson, David B. and Anderson, Sean E. and He, Li-wei and Salesin, David H. and Weld, Daniel S. and Cohen, Michael F.},
 title = {Declarative Camera Control for Automatic Cinematography},
 booktitle = {Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 1},
 series = {AAAI'96},
 year = {1996},
 isbn = {0-262-51091-X},
 location = {Portland, Oregon},
 pages = {148--155},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=1892875.1892897},
 acmid = {1892897},
 publisher = {AAAI Press},
} 

@article{hart1988development,
  title={Development of NASA-TLX (Task Load Index): Results of empirical and theoretical research},
  author={Hart, Sandra G and Staveland, Lowell E},
  journal={Advances in psychology},
  volume={52},
  pages={139--183},
  year={1988},
  publisher={Elsevier},
  doi={10.1016/S0166-4115(08)62386-9}
}

@inproceedings{hart2006nasa,
  title={NASA-task load index (NASA-TLX); 20 years later},
  author={Hart, Sandra G},
  booktitle={Proceedings of the human factors and ergonomics society annual meeting},
  volume={50},
  number={9},
  pages={904--908},
  year={2006},
  organization={Sage Publications Sage CA: Los Angeles, CA},
  doi={10.1177/154193120605000909}
}

@article{cherry2014quantifying,
 author = {Cherry, Erin and Latulipe, Celine},
 title = {Quantifying the Creativity Support of Digital Tools Through the Creativity Support Index},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {August 2014},
 volume = {21},
 number = {4},
 month = jun,
 year = {2014},
 issn = {1073-0516},
 pages = {21:1--21:25},
 articleno = {21},
 numpages = {25},
 doi = {10.1145/2617588},
 acmid = {2617588},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Creativity support tools, evaluation, psychometrics, surveys},
} 

@ARTICLE{dong2015development,
  
AUTHOR={Dong, Mia Y. and Sandberg, Kristian and Bibby, Bo M. and Pedersen, Michael N. and Overgaard, Morten},   
	 
TITLE={The development of a sense of control scale},      
	
JOURNAL={Frontiers in Psychology},      
	
VOLUME={6},      

PAGES={1733},     
	
YEAR={2015},      
	  
URL={https://www.frontiersin.org/article/10.3389/fpsyg.2015.01733},       
	
DOI={10.3389/fpsyg.2015.01733},      
	
ISSN={1664-1078},   
   
ABSTRACT={In the past decades, sense of control – the feeling that one is in control of one’s actions has gained much scientific interests. Various scales have been used to measure sense of control in previous studies, yet no study has allowed participants to create a scale for rating their control experiences despite advances in the neighbouring field of conscious vision has been linked to this approach. Here, we examined how participants preferred to rate sense of control during a simple motor control task by asking them to create a scale to be used to describe their sense of control experience during the task. Scale with 6 steps was most frequently created. Even though some variability was observed in the number of preferred scale steps, descriptions were highly similar across all participants when scales were converted to the same continuum. When we divided participants into groups based on their number of preferred scale steps, mean task performance and sense of control could be described as sigmoid functions of the noise level, and the function parameters were equivalent across groups. We also showed that task performance increased exponentially as a function of control rating, and that, again, function parameters were equivalent for all groups. In summary, the present study established a participant-generated 6-point sense of control rating scale for simple computerized motor control tasks that can be empirically tested against other measures of control in future studies.}
}

@InProceedings{hoesl2017you,
author="Hoesl, Axel
and M{\"o}rwald, Partrick
and Burgdorf, Philipp
and Dre{\ss}ler, Elisabeth
and Butz, Andreas",
editor="Bernhaupt, Regina
and Dalvi, Girish
and Joshi, Anirudha
and K. Balkrishan, Devanuj
and O'Neill, Jacki
and Winckler, Marco",
title="You've Got the Moves, We've Got the Motion -- Understanding and Designing for Cinematographic Camera Motion Control",
booktitle="Human-Computer Interaction - INTERACT 2017",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="523--541",
abstract="Moving a film camera aesthetically is complex, even for professionals. They commonly use mechanical tools which help them to control camera motion. In recent years, computer-controlled tools were developed, but their development is mostly technology-driven and often fails to thoroughly integrate the user perspective. In HCI, prototyping is an established way to collect early feedback and thereby integrate a user perspective early on. In filmmaking, there is a lack of prototyping platforms, mostly due to the small market and inherent technical complexity of tools. We therefore developed a prototyping platform in cooperation between experts in camera operation, mechanical engineering and computer science. It consists of a motion control system for sliding camera moves composed of affordable hardware and open source software, and it supports the wireless connection of various types of user interfaces via Bluetooth. In this combination, it allows the exploration of different interface and control strategies in-the-wild, as it is easy to transport and stable for use in the field. A prototype using our platform was used by professional filmmakers in real commercial assignments. We further report on its use in two studies (N = 18, N = 12) examining the effects of various degrees of automation (low and medium) on the sense and quality of control. Our results indicate no decrease in both dimensions.",
isbn="978-3-319-67744-6",
doi={10.1007/978-3-319-67744-6_33}
}

@misc{online:nielsen2006progressive,
	author = {Nielsen, Jakob},
	title = {Progressive Disclosure},
	year = "2006",
	month = dec,
	url = {https://www.nngroup.com/articles/progressive-disclosure/},
	publisher = {Nielsen Norman Group},
    lastaccessed = "May 3, 2018"
}

@online{online:humaninterfaceguidelinesappleios,
	title = {{Adaptivity and Layout - Visual Design - iOS Human Interface Guidelines}},
	date = {2017-06-05},
	urldate={2018-01-12},
	url = {https://developer.apple.com/ios/human-interface-guidelines/visual-design/adaptivity-and-layout/}
}

@online{online:materialdesignicons,
	title = {{Material icons - Material Design}},
	date = {2018-01-12},
	urldate={2018-01-12},
	url = {https://material.io/icons/}
}

@online{website:komninos2017noui,
	author = {Komninos, Andreas},
	title = {No-UI: How to Build Transparent Interaction},
	url = {https://www.interaction-design.org/literature/article/no-ui-how-to-build-transparent-interaction},
	publisher = {Interaction Design Foundation},
    date = {2017-06},
	urldate={2018-03-26}
}

@inproceedings{lepinski2010design,
  title={The design and evaluation of multitouch marking menus},
  author={Lepinski, G Julian and Grossman, Tovi and Fitzmaurice, George},
  booktitle={Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
  pages={2233--2242},
  year={2010},
  organization={ACM},
  doi={10.1145/1753326.1753663}
}